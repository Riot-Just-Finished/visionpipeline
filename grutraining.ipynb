{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c476bac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pushup Vid 3.mp4\n",
      "  ‚úÖ 12 reps saved to split_reps/Pushup Vid 3\n",
      "Processing: PushUps Vid 1.mp4\n",
      "  ‚úÖ 10 reps saved to split_reps/PushUps Vid 1\n",
      "Processing: PushUps Vid 2.mp4\n",
      "  ‚úÖ 20 reps saved to split_reps/PushUps Vid 2\n",
      "üéâ All videos processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "\n",
    "input_dir = \"My Training Data\\Correct\"\n",
    "output_root = \"split_reps/\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "def extract_landmarks_and_frames(video_path):\n",
    "    \"\"\"Extract pose landmarks + keep raw frames for later video splitting.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    sequence, frames = [], []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb)\n",
    "        if results.pose_landmarks:\n",
    "            frame_landmarks = []\n",
    "            for lm in results.pose_landmarks.landmark:\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z])\n",
    "            sequence.append(frame_landmarks)\n",
    "        else:\n",
    "            # Append dummy frame to keep sync\n",
    "            sequence.append([0]*99)\n",
    "    cap.release()\n",
    "    return np.array(sequence), frames\n",
    "\n",
    "def get_motion_signal(sequence):\n",
    "    \"\"\"Choose the best joint (nose, shoulder, or hip) for motion tracking.\"\"\"\n",
    "    joints = [0, 11, 23]  # nose, left_shoulder, left_hip\n",
    "    motion_signals = []\n",
    "    for j in joints:\n",
    "        y = sequence[:, j * 3 + 1]\n",
    "        y_smooth = np.convolve(y, np.ones(5)/5, mode='same')\n",
    "        motion_signals.append(y_smooth)\n",
    "    ranges = [np.ptp(sig) for sig in motion_signals]\n",
    "    best_idx = np.argmax(ranges)\n",
    "    return motion_signals[best_idx]\n",
    "\n",
    "def split_reps(sequence, signal, frames, save_dir, basename, fps):\n",
    "    \"\"\"Split both the numpy sequence and the original video frames.\"\"\"\n",
    "    minima, _ = find_peaks(-signal, distance=15)\n",
    "    start = 0\n",
    "    rep_count = 0\n",
    "\n",
    "    for m in minima:\n",
    "        end = m + 10\n",
    "        rep_seq = sequence[start:end]\n",
    "        rep_frames = frames[start:end]\n",
    "        if len(rep_seq) > 20:  # ignore too short reps\n",
    "            rep_count += 1\n",
    "\n",
    "            # Save npy\n",
    "            np.save(os.path.join(save_dir, f\"{basename}_rep{rep_count}.npy\"), rep_seq)\n",
    "\n",
    "            # Save video segment\n",
    "            h, w, _ = rep_frames[0].shape\n",
    "            out_path = os.path.join(save_dir, f\"{basename}_rep{rep_count}.mp4\")\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "            for f in rep_frames:\n",
    "                out.write(f)\n",
    "            out.release()\n",
    "        start = end\n",
    "    return rep_count\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    print(\"Processing:\", filename)\n",
    "    video_path = os.path.join(input_dir, filename)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    sequence, frames = extract_landmarks_and_frames(video_path)\n",
    "    if sequence.size == 0:\n",
    "        print(\"  ‚ö†Ô∏è No pose detected, skipping:\", filename)\n",
    "        continue\n",
    "\n",
    "    signal = get_motion_signal(sequence)\n",
    "\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    save_dir = os.path.join(output_root, name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    reps_found = split_reps(sequence, signal, frames, save_dir, name, fps)\n",
    "    print(f\"  ‚úÖ {reps_found} reps saved to {save_dir}\")\n",
    "\n",
    "pose.close()\n",
    "print(\"üéâ All videos processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef7920a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Pushup Vid 3.mp4\n",
      "  ‚úÖ 9 full reps saved to split_reps_full/Pushup Vid 3\n",
      "Processing: PushUps Vid 1.mp4\n",
      "  ‚úÖ 10 full reps saved to split_reps_full/PushUps Vid 1\n",
      "Processing: PushUps Vid 2.mp4\n",
      "  ‚úÖ 20 full reps saved to split_reps_full/PushUps Vid 2\n",
      "üéâ All videos processed successfully.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "\n",
    "input_dir = \"My Training Data\\Correct\"\n",
    "output_root = \"split_reps_full/\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "def extract_landmarks_and_frames(video_path):\n",
    "    \"\"\"Extract pose landmarks + keep raw frames for later video splitting.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    sequence, frames = [], []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb)\n",
    "        if results.pose_landmarks:\n",
    "            frame_landmarks = []\n",
    "            for lm in results.pose_landmarks.landmark:\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z])\n",
    "            sequence.append(frame_landmarks)\n",
    "        else:\n",
    "            # Append dummy frame to keep frame sync\n",
    "            sequence.append([0]*99)\n",
    "    cap.release()\n",
    "    return np.array(sequence), frames\n",
    "\n",
    "def get_motion_signal(sequence):\n",
    "    \"\"\"Choose the best joint (nose, shoulder, or hip) for motion tracking.\"\"\"\n",
    "    joints = [0, 11, 23]  # nose, left_shoulder, left_hip\n",
    "    motion_signals = []\n",
    "    for j in joints:\n",
    "        y = sequence[:, j * 3 + 1]\n",
    "        y_smooth = np.convolve(y, np.ones(7)/7, mode='same')\n",
    "        motion_signals.append(y_smooth)\n",
    "    ranges = [np.ptp(sig) for sig in motion_signals]\n",
    "    best_idx = np.argmax(ranges)\n",
    "    return motion_signals[best_idx]\n",
    "\n",
    "def split_reps(sequence, signal, frames, save_dir, basename, fps):\n",
    "    \"\"\"Split the video into full reps (up ‚Üí down ‚Üí up).\"\"\"\n",
    "    # Find peaks (top/up) and valleys (bottom/down)\n",
    "    peaks, _ = find_peaks(signal, distance=15, prominence=0.01)\n",
    "    valleys, _ = find_peaks(-signal, distance=15, prominence=0.01)\n",
    "\n",
    "    # Combine and sort\n",
    "    extrema = np.sort(np.concatenate([peaks, valleys]))\n",
    "    \n",
    "    rep_count = 0\n",
    "    for i in range(len(extrema) - 1):\n",
    "        start = extrema[i]\n",
    "        end = extrema[i + 1]\n",
    "\n",
    "        # Skip if interval too short\n",
    "        if end - start < 10:\n",
    "            continue\n",
    "\n",
    "        # Detect \"up ‚Üí down ‚Üí up\" pattern\n",
    "        if signal[start] > signal[end]:\n",
    "            # This is the down motion (ignore)\n",
    "            continue\n",
    "\n",
    "        # One full rep between this peak and the next peak\n",
    "        rep_seq = sequence[start:end]\n",
    "        rep_frames = frames[start:end]\n",
    "        rep_count += 1\n",
    "\n",
    "        npy_path = os.path.join(save_dir, f\"{basename}_rep{rep_count}.npy\")\n",
    "        np.save(npy_path, rep_seq)\n",
    "\n",
    "        # Save video\n",
    "        h, w, _ = rep_frames[0].shape\n",
    "        out_path = os.path.join(save_dir, f\"{basename}_rep{rep_count}.mp4\")\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "        for f in rep_frames:\n",
    "            out.write(f)\n",
    "        out.release()\n",
    "\n",
    "    return rep_count\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    print(\"Processing:\", filename)\n",
    "    video_path = os.path.join(input_dir, filename)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    sequence, frames = extract_landmarks_and_frames(video_path)\n",
    "    if sequence.size == 0:\n",
    "        print(\"  ‚ö†Ô∏è No pose detected, skipping:\", filename)\n",
    "        continue\n",
    "\n",
    "    signal = get_motion_signal(sequence)\n",
    "\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    save_dir = os.path.join(output_root, name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    reps_found = split_reps(sequence, signal, frames, save_dir, name, fps)\n",
    "    print(f\"  ‚úÖ {reps_found} full reps saved to {save_dir}\")\n",
    "\n",
    "pose.close()\n",
    "print(\"üéâ All videos processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48033ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Wrong Pushup Vid 1.mp4\n",
      "  ‚úÖ 19 full reps saved to split_reps_full_Wrong/Wrong Pushup Vid 1\n",
      "Processing: Wrong Pushup vid 2.mp4\n",
      "  ‚úÖ 48 full reps saved to split_reps_full_Wrong/Wrong Pushup vid 2\n",
      "Processing: Wrong Pushup Vid 3.mp4\n",
      "  ‚úÖ 9 full reps saved to split_reps_full_Wrong/Wrong Pushup Vid 3\n",
      "Processing: Wrong Pushup VId 4.mp4\n",
      "  ‚úÖ 21 full reps saved to split_reps_full_Wrong/Wrong Pushup VId 4\n",
      "üéâ All videos processed successfully.\n"
     ]
    }
   ],
   "source": [
    "#3rd try\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False)\n",
    "\n",
    "input_dir = \"My Training Data\\Wrong\"\n",
    "output_root = \"split_reps_full_Wrong/\"\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "def extract_landmarks_and_frames(video_path):\n",
    "    \"\"\"Extract pose landmarks + keep raw frames for later video splitting.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    sequence, frames = [], []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(rgb)\n",
    "        if results.pose_landmarks:\n",
    "            frame_landmarks = []\n",
    "            for lm in results.pose_landmarks.landmark:\n",
    "                frame_landmarks.extend([lm.x, lm.y, lm.z])\n",
    "            sequence.append(frame_landmarks)\n",
    "        else:\n",
    "            # Append dummy frame to keep frame sync\n",
    "            sequence.append([0]*99)\n",
    "    cap.release()\n",
    "    return np.array(sequence), frames\n",
    "\n",
    "def get_motion_signal(sequence):\n",
    "    \"\"\"Choose the best joint (nose, shoulder, or hip) for motion tracking.\"\"\"\n",
    "    joints = [0, 11, 23]  # nose, left_shoulder, left_hip\n",
    "    motion_signals = []\n",
    "    for j in joints:\n",
    "        y = sequence[:, j * 3 + 1]\n",
    "        y_smooth = np.convolve(y, np.ones(7)/7, mode='same')\n",
    "        motion_signals.append(y_smooth)\n",
    "    ranges = [np.ptp(sig) for sig in motion_signals]\n",
    "    best_idx = np.argmax(ranges)\n",
    "    return motion_signals[best_idx]\n",
    "\n",
    "def split_reps(sequence, signal, frames, save_dir, basename, fps):\n",
    "    \"\"\"Split video into *both* up‚Üídown‚Üíup and down‚Üíup‚Üídown reps.\"\"\"\n",
    "    peaks, _ = find_peaks(signal, distance=15, prominence=0.01)\n",
    "    valleys, _ = find_peaks(-signal, distance=15, prominence=0.01)\n",
    "\n",
    "    # Merge and sort all extrema\n",
    "    extrema = np.sort(np.concatenate([peaks, valleys]))\n",
    "\n",
    "    rep_count = 0\n",
    "\n",
    "    # Loop through consecutive triples of extrema (A ‚Üí B ‚Üí C)\n",
    "    for i in range(len(extrema) - 2):\n",
    "        a, b, c = extrema[i], extrema[i + 1], extrema[i + 2]\n",
    "\n",
    "        # Basic validity: ensure frames in between\n",
    "        if c - a < 15:\n",
    "            continue\n",
    "\n",
    "        # Check the pattern type:\n",
    "        # Peak-Valley-Peak (up-down-up) or Valley-Peak-Valley (down-up-down)\n",
    "        if (signal[a] > signal[b] and signal[c] > signal[b]) or \\\n",
    "           (signal[a] < signal[b] and signal[c] < signal[b]):\n",
    "\n",
    "            rep_seq = sequence[a:c]\n",
    "            rep_frames = frames[a:c]\n",
    "            rep_count += 1\n",
    "\n",
    "            # Save numpy data\n",
    "            npy_path = os.path.join(save_dir, f\"{basename}_rep{rep_count}.npy\")\n",
    "            np.save(npy_path, rep_seq)\n",
    "\n",
    "            # Save video segment\n",
    "            h, w, _ = rep_frames[0].shape\n",
    "            out_path = os.path.join(save_dir, f\"{basename}_rep{rep_count}.mp4\")\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(out_path, fourcc, fps, (w, h))\n",
    "            for f in rep_frames:\n",
    "                out.write(f)\n",
    "            out.release()\n",
    "\n",
    "    return rep_count\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    if not filename.endswith(\".mp4\"):\n",
    "        continue\n",
    "\n",
    "    print(\"Processing:\", filename)\n",
    "    video_path = os.path.join(input_dir, filename)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    cap.release()\n",
    "\n",
    "    sequence, frames = extract_landmarks_and_frames(video_path)\n",
    "    if sequence.size == 0:\n",
    "        print(\"  ‚ö†Ô∏è No pose detected, skipping:\", filename)\n",
    "        continue\n",
    "\n",
    "    signal = get_motion_signal(sequence)\n",
    "\n",
    "    name = os.path.splitext(filename)[0]\n",
    "    save_dir = os.path.join(output_root, name)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    reps_found = split_reps(sequence, signal, frames, save_dir, name, fps)\n",
    "    print(f\"  ‚úÖ {reps_found} full reps saved to {save_dir}\")\n",
    "\n",
    "pose.close()\n",
    "print(\"üéâ All videos processed successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ff7be0",
   "metadata": {},
   "source": [
    "Putting all into one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "259f2d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84 files\n",
      "Detected max feature count: 99\n",
      "‚úÖ Combined dataset shape: (84, 150, 99)\n",
      "üíæ Saved all_reps_X.npy\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, glob\n",
    "\n",
    "base_dir = \"split_reps_full_thistime/\"\n",
    "output_X = \"all_reps_X.npy\"\n",
    "output_y = \"all_reps_y.npy\"\n",
    "\n",
    "target_frames = 150  # length per rep\n",
    "\n",
    "files = glob.glob(os.path.join(base_dir, \"**/*.npy\"), recursive=True)\n",
    "print(f\"Found {len(files)} files\")\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "max_features = 0\n",
    "\n",
    "# First pass: find max feature dimension\n",
    "for f in files:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "    if data.ndim == 3:\n",
    "        data = data[0] if data.shape[0] == 1 else data\n",
    "    if data.ndim == 2:\n",
    "        max_features = max(max_features, data.shape[1])\n",
    "print(f\"Detected max feature count: {max_features}\")\n",
    "\n",
    "# Second pass: normalize all to same shape\n",
    "for f in files:\n",
    "    data = np.load(f, allow_pickle=True)\n",
    "    if data.ndim == 3:\n",
    "        data = data[0] if data.shape[0] == 1 else data\n",
    "    if data.ndim != 2:\n",
    "        print(f\"‚ö†Ô∏è Skipping invalid: {f}, shape={data.shape}\")\n",
    "        continue\n",
    "\n",
    "    frames, feats = data.shape\n",
    "\n",
    "    # pad features if needed\n",
    "    if feats < max_features:\n",
    "        feat_pad = np.zeros((frames, max_features - feats))\n",
    "        data = np.hstack((data, feat_pad))\n",
    "    elif feats > max_features:\n",
    "        data = data[:, :max_features]\n",
    "\n",
    "    # pad/crop frames\n",
    "    if frames < target_frames:\n",
    "        frame_pad = np.zeros((target_frames - frames, max_features))\n",
    "        data = np.vstack((data, frame_pad))\n",
    "    elif frames > target_frames:\n",
    "        data = data[:target_frames, :]\n",
    "\n",
    "    X.append(data)\n",
    "\n",
    "    # auto-label based on filename\n",
    "    if \"good\" in f.lower():\n",
    "        y.append(1)\n",
    "    elif \"bad\" in f.lower():\n",
    "        y.append(0)\n",
    "\n",
    "X = np.array(X)\n",
    "print(\"‚úÖ Combined dataset shape:\", X.shape)\n",
    "np.save(output_X, X)\n",
    "print(f\"üíæ Saved {output_X}\")\n",
    "\n",
    "if y:\n",
    "    y = np.array(y)\n",
    "    np.save(output_y, y)\n",
    "    print(f\"üíæ Saved {output_y} (labels 0=bad,1=good)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bc66aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.12.0.88-cp37-abi3-win_amd64.whl (39.0 MB)\n",
      "     ---------------------------------------- 0.0/39.0 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/39.0 MB 660.6 kB/s eta 0:00:59\n",
      "     ---------------------------------------- 0.1/39.0 MB 1.3 MB/s eta 0:00:30\n",
      "     ---------------------------------------- 0.2/39.0 MB 2.4 MB/s eta 0:00:17\n",
      "      --------------------------------------- 0.5/39.0 MB 3.7 MB/s eta 0:00:11\n",
      "      --------------------------------------- 0.9/39.0 MB 5.4 MB/s eta 0:00:08\n",
      "     - -------------------------------------- 1.4/39.0 MB 6.3 MB/s eta 0:00:07\n",
      "     - -------------------------------------- 1.8/39.0 MB 7.3 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 2.2/39.0 MB 7.5 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 2.7/39.0 MB 8.1 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 3.1/39.0 MB 8.7 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 3.6/39.0 MB 8.9 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 4.1/39.0 MB 9.0 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 4.5/39.0 MB 9.4 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 4.9/39.0 MB 9.5 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 5.3/39.0 MB 9.5 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 5.9/39.0 MB 9.9 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 6.3/39.0 MB 9.8 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 6.7/39.0 MB 10.0 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 7.2/39.0 MB 10.0 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 7.6/39.0 MB 10.1 MB/s eta 0:00:04\n",
      "     -------- ------------------------------- 8.1/39.0 MB 10.3 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 8.6/39.0 MB 10.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 9.0/39.0 MB 10.3 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 9.5/39.0 MB 10.4 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 10.0/39.0 MB 10.5 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 10.5/39.0 MB 11.3 MB/s eta 0:00:03\n",
      "     ---------- ---------------------------- 10.9/39.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ----------- --------------------------- 11.3/39.0 MB 11.9 MB/s eta 0:00:03\n",
      "     ----------- --------------------------- 11.8/39.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 12.3/39.0 MB 11.5 MB/s eta 0:00:03\n",
      "     ------------ -------------------------- 12.8/39.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 13.2/39.0 MB 11.9 MB/s eta 0:00:03\n",
      "     ------------- ------------------------- 13.7/39.0 MB 11.9 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 14.2/39.0 MB 11.9 MB/s eta 0:00:03\n",
      "     -------------- ------------------------ 14.7/39.0 MB 11.7 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 15.1/39.0 MB 11.7 MB/s eta 0:00:03\n",
      "     --------------- ----------------------- 15.6/39.0 MB 11.7 MB/s eta 0:00:03\n",
      "     ---------------- ---------------------- 16.0/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 16.5/39.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ---------------- ---------------------- 17.0/39.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 17.4/39.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ----------------- --------------------- 17.9/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 18.4/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------ -------------------- 18.9/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 19.4/39.0 MB 11.9 MB/s eta 0:00:02\n",
      "     ------------------- ------------------- 20.0/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 20.5/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------------- ------------------ 20.9/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 21.4/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------- ----------------- 21.9/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 22.3/39.0 MB 11.5 MB/s eta 0:00:02\n",
      "     ---------------------- ---------------- 22.8/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 23.2/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ----------------------- --------------- 23.7/39.0 MB 11.5 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 24.2/39.0 MB 11.5 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 24.6/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------------ -------------- 25.0/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 25.5/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     ------------------------- ------------- 25.9/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 26.4/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------ 26.9/39.0 MB 11.7 MB/s eta 0:00:02\n",
      "     --------------------------- ----------- 27.5/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 28.0/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 28.4/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 28.8/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 29.3/39.0 MB 11.5 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 29.8/39.0 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 30.3/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 30.8/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 31.3/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 31.8/39.0 MB 11.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 32.3/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 32.7/39.0 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 33.2/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 33.7/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 34.1/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 34.7/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 35.2/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 35.7/39.0 MB 11.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 36.1/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 36.6/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 37.1/39.0 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 37.7/39.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.6/39.0 MB 11.9 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.0/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  39.0/39.0 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------------------------------- 39.0/39.0 MB 10.6 MB/s eta 0:00:00\n",
      "Collecting numpy<2.3.0,>=2\n",
      "  Using cached numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "Successfully installed numpy-2.2.6 opencv-python-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.21 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n",
      "mediapipe 0.10.21 requires protobuf<5,>=4.25.3, but you have protobuf 6.33.0 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de047157",
   "metadata": {},
   "source": [
    "Mixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0f6451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Loading files...\n",
      "Old data shape (before conversion): (50, 150, 22, 3)\n",
      "New data shape: (84, 150, 33, 3)\n",
      "üîπ Converting old data to 33-landmark format...\n",
      "üîπ Merging both datasets...\n",
      "‚úÖ Merged dataset saved to: merged_X.npy\n",
      "   Total samples: 134\n",
      "   Frames per sample: 150\n",
      "   Features per frame: 99\n",
      "üéâ Conversion + Merge Complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ======== CONFIG ========\n",
    "old_file = \"Training Data VSP\\labels\\correct.npy\"          # old 22-landmark data\n",
    "new_file = \"all_reps_X.npy\"       # new 33-landmark data\n",
    "merged_output = \"merged_X.npy\"    # output combined file\n",
    "# =========================\n",
    "\n",
    "print(\"üîπ Loading files...\")\n",
    "old_data = np.load(old_file, allow_pickle=True)\n",
    "new_data = np.load(new_file, allow_pickle=True)\n",
    "\n",
    "# ======== Handle old data ========\n",
    "if old_data.ndim == 3 and old_data.shape[-1] == 66:\n",
    "    # (samples, frames, 66) ‚Üí reshape to (samples, frames, 22, 3)\n",
    "    old_data = old_data.reshape(old_data.shape[0], old_data.shape[1], 22, 3)\n",
    "elif old_data.ndim == 2 and old_data.shape[-1] == 66:\n",
    "    # (frames, 66)\n",
    "    old_data = old_data.reshape(1, old_data.shape[0], 22, 3)\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected old data shape: {old_data.shape}\")\n",
    "\n",
    "# ======== Handle new data ========\n",
    "if new_data.ndim == 3 and new_data.shape[-1] == 99:\n",
    "    new_data = new_data.reshape(new_data.shape[0], new_data.shape[1], 33, 3)\n",
    "elif new_data.ndim == 2 and new_data.shape[-1] == 99:\n",
    "    new_data = new_data.reshape(1, new_data.shape[0], 33, 3)\n",
    "else:\n",
    "    raise ValueError(f\"Unexpected new data shape: {new_data.shape}\")\n",
    "\n",
    "print(f\"Old data shape (before conversion): {old_data.shape}\")\n",
    "print(f\"New data shape: {new_data.shape}\")\n",
    "\n",
    "# ======== CONVERT OLD 22 ‚Üí 33 landmarks ========\n",
    "print(\"üîπ Converting old data to 33-landmark format...\")\n",
    "num_samples, frames, _, _ = old_data.shape\n",
    "converted_old = np.zeros((num_samples, frames, 33, 3), dtype=np.float32)\n",
    "converted_old[:, :, :22, :] = old_data  # copy old joints, pad remaining 11 with zeros\n",
    "\n",
    "# Flatten both into (samples, frames, 99)\n",
    "converted_old_flat = converted_old.reshape(num_samples, frames, 99)\n",
    "new_data_flat = new_data.reshape(new_data.shape[0], new_data.shape[1], 99)\n",
    "\n",
    "# ======== Combine datasets ========\n",
    "print(\"üîπ Merging both datasets...\")\n",
    "merged = np.concatenate([converted_old_flat, new_data_flat], axis=0)\n",
    "np.save(merged_output, merged)\n",
    "\n",
    "print(f\"‚úÖ Merged dataset saved to: {merged_output}\")\n",
    "print(f\"   Total samples: {merged.shape[0]}\")\n",
    "print(f\"   Frames per sample: {merged.shape[1]}\")\n",
    "print(f\"   Features per frame: {merged.shape[2]}\")\n",
    "print(\"üéâ Conversion + Merge Complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visionpipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
